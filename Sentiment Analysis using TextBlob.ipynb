{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-09-15T15:09:40.992813Z","iopub.status.idle":"2024-09-15T15:09:40.993447Z","shell.execute_reply":"2024-09-15T15:09:40.993147Z","shell.execute_reply.started":"2024-09-15T15:09:40.993112Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T15:13:14.790734Z","iopub.status.busy":"2024-09-15T15:13:14.790293Z","iopub.status.idle":"2024-09-15T15:13:14.890447Z","shell.execute_reply":"2024-09-15T15:13:14.889310Z","shell.execute_reply.started":"2024-09-15T15:13:14.790693Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>post_id</th>\n","      <th>post_created</th>\n","      <th>post_text</th>\n","      <th>user_id</th>\n","      <th>followers</th>\n","      <th>friends</th>\n","      <th>favourites</th>\n","      <th>statuses</th>\n","      <th>retweets</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>637894677824413696</td>\n","      <td>Sun Aug 30 07:48:37 +0000 2015</td>\n","      <td>It's just over 2 years since I was diagnosed w...</td>\n","      <td>1013187241</td>\n","      <td>84</td>\n","      <td>211</td>\n","      <td>251</td>\n","      <td>837</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>637890384576778240</td>\n","      <td>Sun Aug 30 07:31:33 +0000 2015</td>\n","      <td>It's Sunday, I need a break, so I'm planning t...</td>\n","      <td>1013187241</td>\n","      <td>84</td>\n","      <td>211</td>\n","      <td>251</td>\n","      <td>837</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>637749345908051968</td>\n","      <td>Sat Aug 29 22:11:07 +0000 2015</td>\n","      <td>Awake but tired. I need to sleep but my brain ...</td>\n","      <td>1013187241</td>\n","      <td>84</td>\n","      <td>211</td>\n","      <td>251</td>\n","      <td>837</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>637696421077123073</td>\n","      <td>Sat Aug 29 18:40:49 +0000 2015</td>\n","      <td>RT @SewHQ: #Retro bears make perfect gifts and...</td>\n","      <td>1013187241</td>\n","      <td>84</td>\n","      <td>211</td>\n","      <td>251</td>\n","      <td>837</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>637696327485366272</td>\n","      <td>Sat Aug 29 18:40:26 +0000 2015</td>\n","      <td>It’s hard to say whether packing lists are mak...</td>\n","      <td>1013187241</td>\n","      <td>84</td>\n","      <td>211</td>\n","      <td>251</td>\n","      <td>837</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0             post_id                    post_created  \\\n","0           0  637894677824413696  Sun Aug 30 07:48:37 +0000 2015   \n","1           1  637890384576778240  Sun Aug 30 07:31:33 +0000 2015   \n","2           2  637749345908051968  Sat Aug 29 22:11:07 +0000 2015   \n","3           3  637696421077123073  Sat Aug 29 18:40:49 +0000 2015   \n","4           4  637696327485366272  Sat Aug 29 18:40:26 +0000 2015   \n","\n","                                           post_text     user_id  followers  \\\n","0  It's just over 2 years since I was diagnosed w...  1013187241         84   \n","1  It's Sunday, I need a break, so I'm planning t...  1013187241         84   \n","2  Awake but tired. I need to sleep but my brain ...  1013187241         84   \n","3  RT @SewHQ: #Retro bears make perfect gifts and...  1013187241         84   \n","4  It’s hard to say whether packing lists are mak...  1013187241         84   \n","\n","   friends  favourites  statuses  retweets  label  \n","0      211         251       837         0      1  \n","1      211         251       837         1      1  \n","2      211         251       837         0      1  \n","3      211         251       837         2      1  \n","4      211         251       837         1      1  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","import spacy\n","from textblob import TextBlob\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","from gensim import corpora\n","from gensim.models import LdaModel\n","from nltk.corpus import stopwords\n","import re\n","\n","# Load the dataset\n","url = \"/kaggle/input/mental-health-social-media/Mental-Health-Twitter.csv\"\n","df = pd.read_csv(url)  # Adjust this as per the correct file access\n","\n","# Inspect the dataset\n","df.head()\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T15:14:07.223379Z","iopub.status.busy":"2024-09-15T15:14:07.222966Z","iopub.status.idle":"2024-09-15T15:16:39.497406Z","shell.execute_reply":"2024-09-15T15:16:39.496182Z","shell.execute_reply.started":"2024-09-15T15:14:07.223341Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["# Initialize stopwords and spaCy model\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Define preprocessing function\n","def preprocess_text(text):\n","    text = text.lower()\n","    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n","    tokens = nltk.word_tokenize(text)\n","    tokens = [word for word in tokens if word not in stop_words]\n","    doc = nlp(' '.join(tokens))\n","    lemmatized = [token.lemma_ for token in doc]\n","    return ' '.join(lemmatized)\n","\n","# Apply preprocessing\n","df['cleaned_text'] = df['post_text'].apply(preprocess_text)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T15:17:12.889447Z","iopub.status.busy":"2024-09-15T15:17:12.888984Z","iopub.status.idle":"2024-09-15T15:17:16.705330Z","shell.execute_reply":"2024-09-15T15:17:16.703691Z","shell.execute_reply.started":"2024-09-15T15:17:12.889407Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cleaned_text</th>\n","      <th>textblob_sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2 year since diagnose anxiety depression today...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sunday need break I m plan spend little time p...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>awake tired need sleep brain idea</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>rt sewhq retro bear make perfect gift great be...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>hard say whether pack list make life easy rein...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        cleaned_text textblob_sentiment\n","0  2 year since diagnose anxiety depression today...           positive\n","1  sunday need break I m plan spend little time p...           negative\n","2                  awake tired need sleep brain idea           negative\n","3  rt sewhq retro bear make perfect gift great be...           positive\n","4  hard say whether pack list make life easy rein...           positive"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Apply sentiment analysis using TextBlob\n","df['textblob_polarity'] = df['cleaned_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n","\n","# Classify polarity into positive, negative, and neutral\n","def classify_sentiment(polarity):\n","    if polarity > 0:\n","        return 'positive'\n","    elif polarity < 0:\n","        return 'negative'\n","    else:\n","        return 'neutral'\n","\n","df['textblob_sentiment'] = df['textblob_polarity'].apply(classify_sentiment)\n","\n","# Check results\n","df[['cleaned_text', 'textblob_sentiment']].head()\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T15:20:44.751219Z","iopub.status.busy":"2024-09-15T15:20:44.750321Z","iopub.status.idle":"2024-09-15T15:21:04.502185Z","shell.execute_reply":"2024-09-15T15:21:04.500920Z","shell.execute_reply.started":"2024-09-15T15:20:44.751169Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8776666666666667\n","              precision    recall  f1-score   support\n","\n","          -1       0.92      0.67      0.77      1099\n","           0       0.84      0.99      0.91      2943\n","           1       0.94      0.83      0.88      1958\n","\n","    accuracy                           0.88      6000\n","   macro avg       0.90      0.83      0.85      6000\n","weighted avg       0.89      0.88      0.87      6000\n","\n"]}],"source":["# Label encoding for machine learning (use manually labeled data or rule-based labels for supervised learning)\n","df['label'] = df['textblob_sentiment'].map({'positive': 1, 'negative': -1, 'neutral': 0})\n","\n","# TF-IDF Vectorization\n","tfidf = TfidfVectorizer(max_features=3000)\n","X = tfidf.fit_transform(df['cleaned_text']).toarray()\n","y = df['label']\n","\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Train a Logistic Regression model\n","clf = LogisticRegression(max_iter=1000)\n","clf.fit(X_train, y_train)\n","\n","# Predict and evaluate\n","y_pred = clf.predict(X_test)\n","print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n","print(classification_report(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T15:21:33.325503Z","iopub.status.busy":"2024-09-15T15:21:33.325069Z","iopub.status.idle":"2024-09-15T15:22:06.840950Z","shell.execute_reply":"2024-09-15T15:22:06.839600Z","shell.execute_reply.started":"2024-09-15T15:21:33.325464Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(0, '0.010*\"depression\" + 0.004*\"buy\" + 0.004*\"all\" + 0.004*\"president\" + 0.004*\"treatment\"')\n","(1, '0.032*\"not\" + 0.020*\"do\" + 0.013*\"I\" + 0.013*\"get\" + 0.012*\"like\"')\n","(2, '0.022*\"s\" + 0.020*\"rt\" + 0.014*\"m\" + 0.013*\"I\" + 0.011*\"hello\"')\n","(3, '0.052*\"rt\" + 0.016*\"yong\" + 0.011*\"_\" + 0.009*\"fuck\" + 0.006*\"foryong\"')\n","(4, '0.029*\"thank\" + 0.025*\"follow\" + 0.017*\"say\" + 0.015*\"twitter\" + 0.014*\"rt\"')\n"]}],"source":["# Prepare data for LDA\n","texts = [text.split() for text in df['cleaned_text']]\n","\n","# Create a dictionary and corpus\n","dictionary = corpora.Dictionary(texts)\n","corpus = [dictionary.doc2bow(text) for text in texts]\n","\n","# Train LDA Model\n","lda_model = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=10)\n","\n","# Print the topics\n","topics = lda_model.print_topics(num_words=5)\n","for topic in topics:\n","    print(topic)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T15:22:51.303089Z","iopub.status.busy":"2024-09-15T15:22:51.302654Z","iopub.status.idle":"2024-09-15T15:22:55.159831Z","shell.execute_reply":"2024-09-15T15:22:55.158604Z","shell.execute_reply.started":"2024-09-15T15:22:51.303050Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["TextBlob - Accuracy: 1.00, Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n"]}],"source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from textblob import TextBlob\n","\n","# Function to classify sentiment using TextBlob\n","def classify_textblob_sentiment(text):\n","    polarity = TextBlob(text).sentiment.polarity\n","    if polarity > 0:\n","        return 1  # Positive sentiment\n","    elif polarity < 0:\n","        return -1  # Negative sentiment\n","    else:\n","        return 0  # Neutral sentiment\n","\n","# Apply the classification to the dataset\n","df['textblob_pred'] = df['cleaned_text'].apply(classify_textblob_sentiment)\n","\n","# Get actual labels and predicted labels\n","y_true = df['label']  # Assuming 'label' contains the actual sentiment labels\n","y_pred_textblob = df['textblob_pred']\n","\n","# Calculate TextBlob performance metrics\n","accuracy_textblob = accuracy_score(y_true, y_pred_textblob)\n","precision_textblob, recall_textblob, f1_textblob, _ = precision_recall_fscore_support(y_true, y_pred_textblob, average='weighted')\n","\n","# Print performance metrics\n","print(f\"TextBlob - Accuracy: {accuracy_textblob:.2f}, Precision: {precision_textblob:.2f}, Recall: {recall_textblob:.2f}, F1 Score: {f1_textblob:.2f}\")\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T15:23:16.713586Z","iopub.status.busy":"2024-09-15T15:23:16.713085Z","iopub.status.idle":"2024-09-15T15:23:36.730433Z","shell.execute_reply":"2024-09-15T15:23:36.729254Z","shell.execute_reply.started":"2024-09-15T15:23:16.713536Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression - Accuracy: 0.88, Precision: 0.89, Recall: 0.88, F1 Score: 0.87\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","\n","# TF-IDF Vectorization\n","tfidf = TfidfVectorizer(max_features=3000)\n","X = tfidf.fit_transform(df['cleaned_text']).toarray()\n","y = df['sentiment_label']\n","\n","# Train-Test Split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Train Logistic Regression Classifier\n","clf = LogisticRegression(max_iter=1000)\n","clf.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred_lr = clf.predict(X_test)\n","\n","# Calculate Logistic Regression performance metrics\n","accuracy_lr = accuracy_score(y_test, y_pred_lr)\n","precision_lr, recall_lr, f1_lr, _ = precision_recall_fscore_support(y_test, y_pred_lr, average='weighted')\n","\n","print(f\"Logistic Regression - Accuracy: {accuracy_lr:.2f}, Precision: {precision_lr:.2f}, Recall: {recall_lr:.2f}, F1 Score: {f1_lr:.2f}\")\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":2391573,"sourceId":4036782,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
